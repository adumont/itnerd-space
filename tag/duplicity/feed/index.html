<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>duplicity &#8211; IT Nerd Space</title>
	<atom:link href="http://itnerd.space/tag/duplicity/feed/" rel="self" type="application/rss+xml" />
	<link>http://itnerd.space</link>
	<description>Blog about Cloud, Automation, Android, Smart things...</description>
	<lastBuildDate>Tue, 11 Jul 2017 19:44:22 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.8</generator>

<image>
	<url>https://i2.wp.com/itnerd.space/wp-content/uploads/2016/10/cropped-99789e30b0a6eac11f33246750ca29f9.jpg?fit=32%2C32</url>
	<title>duplicity &#8211; IT Nerd Space</title>
	<link>http://itnerd.space</link>
	<width>32</width>
	<height>32</height>
</image> 
<site xmlns="com-wordpress:feed-additions:1">119014820</site>	<item>
		<title>Offsite Linux backup to Mega with duplicity</title>
		<link>http://itnerd.space/2016/10/26/offsite-backup-with-duplicity-and-mega/</link>
		<comments>http://itnerd.space/2016/10/26/offsite-backup-with-duplicity-and-mega/#respond</comments>
		<pubDate>Wed, 26 Oct 2016 23:22:10 +0000</pubDate>
		<dc:creator><![CDATA[Alex D.]]></dc:creator>
				<category><![CDATA[Cloud]]></category>
		<category><![CDATA[How-to]]></category>
		<category><![CDATA[Linux]]></category>
		<category><![CDATA[backup]]></category>
		<category><![CDATA[cloud]]></category>
		<category><![CDATA[docker]]></category>
		<category><![CDATA[duplicity]]></category>
		<category><![CDATA[mega]]></category>

		<guid isPermaLink="false">http://itnerd.space/?p=7</guid>
		<description><![CDATA[This is about a small personal initiative: I was looking for a solution to backup some Linux servers that I have, at home and in the cloud. Ideally, my requirements were: Backup should be offsite, preferably in the cloud Solution should support some kind of backup policies (full, incremental, and&#8230; ]]></description>
				<content:encoded><![CDATA[<p>This is about a small personal initiative: I was looking for a solution to backup some Linux servers that I have, at home and in the cloud.</p>
<p>Ideally, my requirements were:</p>
<ul>
<li>Backup should be offsite, preferably in the cloud</li>
<li>Solution should support some kind of backup policies (full, incremental, and retention time)</li>
<li>Solution should be secure, so support encryption</li>
<li>Solution should be portable, so same solution would play nicely with the servers, not mess with their OS (dependencies,&#8230;)</li>
<li>Solution should be as cheap as possible (or ideally free!)</li>
</ul>
<p><span id="more-7"></span></p>
<p>For the offsite storage I first though of using AWS Glacier, a cloud storage meant for cold data that you archive, and don&#8217;t need to retrieve often, but the cost was not so cheap. While storage in itself was not too expensive, the cost of retrieving the data (in case you want to restore, which is the point of having a backup, right?), was kind of prohibitive (for the budget I had in mind). So I started to look for alternatives.</p>
<p>For the backup solution, I wanted to use <a href="http://duplicity.nongnu.org/" target="_blank">duplicity</a>. Duplicity supports full and incremental backups, using the rsync protocol, and have support for a lot of storage backend: file, FTP, SSH, AWS S3, Azure, Dropbox, OneDrive, Mega,&#8230; Most of those backends are either illimited but paid services, or free but rather limited (in capacity) storage. All but Mega, which offer for free 50GB of storage, which is quite nice for backup purpose. Perfect fit in my case.</p>
<p>Regarding the portability requirement, I love Docker containers, and all I deploy now for my personal projects is Dockerized. This wasn&#8217;t going to be an exception. Especially I&#8217;d hate to install all kind of dependencies for duplicity and the storage backend plugins in all my servers!</p>
<p>So Docker it would be.</p>
<p>Now back to the storage layer in our solution: although duplicity supposedly have support for a Mega backend, it seems Mega changed their API/SDK, and the current plugin is not working anymore, and would need to be reworked totally. So as an alternative, I turned to using MegaFuse, a Fuse module to mount Mega storage in Linux: so the idea is we first mount the Mega account as a filesystem in Linux, and then we use it as destination of our backup with duplicity (using the file backend). Not as cool as having duplicity talk directly to Mega, but that seems to work equally.</p>
<p>So to recap, we have a container with duplicity and MegaFuse. As the container is stateless, we&#8217;ll map some volumes from the host to the container so the container gets the needed information:</p>
<ul>
<li>/vol/dupmega/megafuse.conf, containing some config for MegaFuse, like the credentials to the Mega account (see below),</li>
<li>As duplicity and MegaFuse both keep a local cache with some metadata, having those stored in the container would do no good, so I also put that in host mapped folder (/vol/dupmega/cache/duplicity/ and /vol/dupmega/cache/megafuse/)</li>
<li>Of course, we want to backup the host, not the container, so we need to map that as well into the container to /source</li>
</ul>
<p>The megafuse.conf contains:</p>
<p><code>USERNAME = username@domain.com<br />
PASSWORD = aV3ryComplexMegaP4ssw0rd<br />
MOUNTPOINT = /mega<br />
CACHEPATH = /dupmega/cache/megafuse<br />
</code><br />
So the Mega account is mounted in /mega in the container, and the MegaFuse cache will be in /dupmega/cache/megafuse (host mounted volume).</p>
<p>Here is the Dockerfile I have used to create my duplicity container with MegaFuse support. Right now it&#8217;s not yet published to Docker Hub. Right now it&#8217;s very rudimentary, there&#8217;s not even a CMD.</p>
<p><code>FROM ubuntu:14.04<br />
MAINTAINER Alexandre Dumont &lt;adumont@gmail.com&gt;</code></p>
<p>ENV DEBIAN_FRONTEND=noninteractive</p>
<p>RUN sed -i -e &#8216;/^deb-src/ s/^/#/&#8217; /etc/apt/sources.list &amp;&amp; \<br />
echo &#8220;force-unsafe-io&#8221; &gt; /etc/dpkg/dpkg.cfg.d/02apt-speedup &amp;&amp; \<br />
echo &#8220;Acquire::http {No-Cache=True;};&#8221; &gt; /etc/apt/apt.conf.d/no-cache &amp;&amp; \<br />
apt-get update &amp;&amp; \<br />
apt-get -qy dist-upgrade &amp;&amp; \<br />
apt-get install -y libcrypto++-dev libcurl4-openssl-dev libfreeimage-dev libreadline-dev libfuse-dev libdb++-dev duplicity git g++ make &amp;&amp; \<br />
apt-get clean &amp;&amp; \<br />
rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* &amp;&amp; \<br />
git clone https://github.com/matteoserva/MegaFuse &amp;&amp; \<br />
cd MegaFuse &amp;&amp; \<br />
make</p>
<p>I use the following command to build the image:</p>
<p><code>docker build -t adumont/dupmega --no-cache=true .</code></p>
<p>And here&#8217;s the image:</p>
<p><code>REPOSITORY TAG IMAGE ID CREATED SIZE<br />
adumont/dupmega latest 3bf1d313aa56 7 days ago 581.8 MB<br />
</code></p>
<p>I still have to work on simplifying the whole process of running a backup. For now, I do it rather manually, but it will become a script and be scheduled in cron most likely.</p>
<p>Right now that&#8217;s how I run it, notice the volume mapping from host to containers. Also notice the container has to run as privileged, so it can use Fuse from inside the container. The source to be backed up is mounted read-only (least privilege).</p>
<p><code>host# docker run --rm -h $( hostname ) -ti --privileged \<br />
-v /vol/dupmega:/dupmega \<br />
-v /root/.gnupg:/root/.gnupg \<br />
-v /vol/dupmega/cache/duplicity:/root/.cache/duplicity \<br />
-v /:/source:ro adumont/dupmega<br />
</code></p>
<p>Then from inside the container, I run:</p>
<p><code>mkdir /mega; MegaFuse/MegaFuse -c /dupmega/megafuse.conf &amp;&gt;/dev/null &amp;<br />
sleep 10<br />
[ -d /mega/backups/$(hostname) ] || exit 1</p>
<p>export PASSPHRASE=AnotherVeryComplexPassphaseForGPGEncrypti0n</code></p>
<p>and finally the duplicity command which will backup /source to /mega. The command is different for each server, as I tweak which files/folders I want to include/exclude in the backup:</p>
<p><code>duplicity --asynchronous-upload \<br />
--include=/source/var/lib/docker/containers \<br />
--include=/source/var/lib/plexmediaserver/Library/Application\ Support/Plex\ Media\ Server/Preferences.xml \<br />
--exclude=/source/dev \<br />
--exclude=/source/proc \<br />
--exclude=/source/run \<br />
--exclude=/source/sys \<br />
--exclude=/source/zfs \<br />
--exclude=/source/mnt \<br />
--exclude=/source/media \<br />
--exclude=/source/vol/dupmega/cache \<br />
--exclude=/source/tank \<br />
--exclude=/source/vbox \<br />
--exclude=/source/var/lib/docker \<br />
--exclude=/source/var/lib/plexmediaserver/ \<br />
--exclude=/source/tmp \<br />
--exclude=/source/var/tmp \<br />
--exclude=/source/var/cache \<br />
--exclude=/source/var/log \<br />
/source/ file:///mega/backups/$(hostname)/ -v info<br />
</code></p>
<p>And this would be a sample output:</p>
<p><code>Local and Remote metadata are synchronized, no sync needed.<br />
Last full backup date: Thu Oct 20 22:51:23 2016<br />
Deleting /tmp/duplicity-Cwz5Ju-tempdir/mktemp-0lEM40-2<br />
Using temporary directory /root/.cache/duplicity/185b874acbbae73c5807a4cc767e4967/duplicity-kYzeVT-tempdir<br />
Using temporary directory /root/.cache/duplicity/185b874acbbae73c5807a4cc767e4967/duplicity-jWJXmd-tempdir<br />
AsyncScheduler: instantiating at concurrency 1<br />
M boot/grub/grubenv<br />
A etc<br />
A etc/apparmor.d/cache<br />
M etc/apparmor.d/cache/docker<br />
[...]<br />
---------------[ Backup Statistics ]--------------<br />
StartTime 1477499247.82 (Wed Oct 26 16:27:27 2016)<br />
EndTime 1477499514.97 (Wed Oct 26 16:31:54 2016)<br />
ElapsedTime 267.15 (4 minutes 27.15 seconds)<br />
SourceFiles 449013<br />
SourceFileSize 3239446764 (3.02 GB)<br />
NewFiles 75<br />
NewFileSize 189457 (185 KB)<br />
DeletedFiles 135<br />
ChangedFiles 68<br />
ChangedFileSize 176144101 (168 MB)<br />
ChangedDeltaSize 0 (0 bytes)<br />
DeltaEntries 278<br />
RawDeltaSize 9317325 (8.89 MB)<br />
TotalDestinationSizeChange 1913375 (1.82 MB)<br />
Errors 0<br />
-------------------------------------------------<br />
</code></p>
<p>And backup are really stored on Mega <img src="https://s.w.org/images/core/emoji/2.3/72x72/1f609.png" alt="😉" class="wp-smiley" style="height: 1em; max-height: 1em;" /> :</p>
<p><a href="https://i2.wp.com/itnerd.space/wp-content/uploads/2016/10/Screenshot-from-2016-10-27-01-10-42.png"><img data-attachment-id="13" data-permalink="http://itnerd.space/2016/10/26/offsite-backup-with-duplicity-and-mega/screenshot-from-2016-10-27-01-10-42/" data-orig-file="https://i2.wp.com/itnerd.space/wp-content/uploads/2016/10/Screenshot-from-2016-10-27-01-10-42.png?fit=1304%2C747" data-orig-size="1304,747" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-from-2016-10-27-01-10-42" data-image-description="" data-medium-file="https://i2.wp.com/itnerd.space/wp-content/uploads/2016/10/Screenshot-from-2016-10-27-01-10-42.png?fit=300%2C172" data-large-file="https://i2.wp.com/itnerd.space/wp-content/uploads/2016/10/Screenshot-from-2016-10-27-01-10-42.png?fit=700%2C401" class="aligncenter wp-image-13 size-large" src="https://i2.wp.com/itnerd.space/wp-content/uploads/2016/10/Screenshot-from-2016-10-27-01-10-42.png?resize=700%2C401" alt="backup files on Mega" srcset="https://i2.wp.com/itnerd.space/wp-content/uploads/2016/10/Screenshot-from-2016-10-27-01-10-42.png?resize=1024%2C587 1024w, https://i2.wp.com/itnerd.space/wp-content/uploads/2016/10/Screenshot-from-2016-10-27-01-10-42.png?resize=300%2C172 300w, https://i2.wp.com/itnerd.space/wp-content/uploads/2016/10/Screenshot-from-2016-10-27-01-10-42.png?resize=768%2C440 768w, https://i2.wp.com/itnerd.space/wp-content/uploads/2016/10/Screenshot-from-2016-10-27-01-10-42.png?w=1304 1304w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" /></a></p>
]]></content:encoded>
			<wfw:commentRss>http://itnerd.space/2016/10/26/offsite-backup-with-duplicity-and-mega/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
	<post-id xmlns="com-wordpress:feed-additions:1">7</post-id>	</item>
	</channel>
</rss>

<!-- Performance optimized by W3 Total Cache. Learn more: https://www.w3-edge.com/products/

Object Caching 1208/1212 objects using disk
Page Caching using disk: enhanced
Database Caching 2/7 queries in 0.003 seconds using disk

 Served from: itnerd.space @ 2017-07-13 21:36:54 by W3 Total Cache -->